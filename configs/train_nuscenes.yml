experiment_name: "'train_nuscenes'"

data:
  train:
    module: torch.utils.data
    name: DataLoader
    kwargs:
      dataset:
        module: datasets.nuscenes_dataset
        name: NuScenesDataset
        kwargs:
          version: "'v1.0-trainval'"
          dataroot: "'../../datasets/nuscenes'"
          cam_names:
            - "'CAM_FRONT'"
            - "'CAM_FRONT_LEFT'"
            - "'CAM_FRONT_RIGHT'"
            - "'CAM_BACK_LEFT'"
            - "'CAM_BACK_RIGHT'"
            - "'CAM_BACK'"
          verbose: True
          token_list_file: "'datasets/file_lists/nuscenes/train.txt'"
          mask_dir: "'datasets/masks/nuscenes'"
          image_shape: (640, 352)
          jittering: (0.2, 0.2, 0.2, 0.05)
          ref_extrinsic_idx: 0
          length: 0
      shuffle: True
      batch_size: 2
      num_workers: 6

  # valid:
  #   module: torch.utils.data
  #   name: DataLoader
  #   kwargs:
  #     dataset:
  #       module: datasets.nuscenes_dataset
  #       name: NuScenesDataset
  #       kwargs:
  #         version: "'v1.0-trainval'"
  #         dataroot: "'../../datasets/nuscenes'"
  #         cam_names:
  #           - "'CAM_FRONT'"
  #           - "'CAM_FRONT_LEFT'"
  #           - "'CAM_FRONT_RIGHT'"
  #           - "'CAM_BACK_LEFT'"
  #           - "'CAM_BACK_RIGHT'"
  #           - "'CAM_BACK'"
  #         verbose: True
  #         token_list_file: "'datasets/file_lists/nuscenes/val.txt'"
  #         mask_dir: "'datasets/masks/nuscenes'"
  #         image_shape: (640, 352)
  #         jittering: (0.0, 0.0, 0.0, 0.0)
  #         ref_extrinsic_idx: 0
  #         length: 0
  #     shuffle: False
  #     batch_size: 4
  #     num_workers: 8

  # valid_train:
  #   module: torch.utils.data
  #   name: DataLoader
  #   kwargs:
  #     dataset:
  #       module: datasets.nuscenes_dataset
  #       name: NuScenesDataset
  #       kwargs:
  #         version: "'v1.0-trainval'"
  #         dataroot: "'../../datasets/nuscenes'"
  #         cam_names:
  #           - "'CAM_FRONT'"
  #           - "'CAM_FRONT_LEFT'"
  #           - "'CAM_FRONT_RIGHT'"
  #           - "'CAM_BACK_LEFT'"
  #           - "'CAM_BACK_RIGHT'"
  #           - "'CAM_BACK'"
  #         verbose: True
  #         token_list_file: "'datasets/file_lists/nuscenes/val_vis.txt'"
  #         mask_dir: "'datasets/masks/nuscenes'"
  #         image_shape: (640, 352)
  #         jittering: (0.0, 0.0, 0.0, 0.0)
  #         ref_extrinsic_idx: 0
  #         length: 0
  #     shuffle: False
  #     batch_size: 4
  #     num_workers: 8

model:
  module: models.vf_depth
  name: VFDepth

optimizer:
  module: torch.optim
  name: Adam
  kwargs:
    params: model.parameters()
    lr: 0.0001

loss_computation_wrapper:
  module: losses.loss_computation_wrapper
  name: LossComputationWrapper
  kwargs:
    model: model
    loss_fn:
      module: losses.multi_cam_loss
      name: MultiCamLoss
      kwargs:
        disparity_smoothness: 0.001
        spatio_coeff: 0.03
        spatio_tempo_coeff: 0.1
    max_depth: 80.0
    min_depth: 1.5
    focal_length_scale: 300.0
    neighbor_cam_indices_map:
      0: [1, 2]
      1: [0, 3]
      2: [0, 4]
      3: [1, 5]
      4: [2, 5]
      5: [3, 4]

loss_fn:
  module: flame.loss
  name: Loss
  kwargs:
    loss_fn: loss_computation_wrapper
    output_transform: >
      lambda output: (
        output[1][7], # org_prev_images
        output[1][8], # org_cur_images
        output[1][9], # org_next_images
        output[1][3], # masks
        output[0][2], # depth_maps
        output[1][4], # intrinsics
        output[1][5], # extrinsics
        output[0][0], # cur_to_prev_poses
        output[0][1], # cur_to_next_poses
      )

engine:
  module: flame.engine
  name: Trainer.factory
  kwargs:
    model: model
    data: data.train
    optimizer: optimizer
    loss_fn: loss_fn
    device: "'cuda'"
    max_epochs: 10
    prepare_batch: prepare_batch
    model_fn: >
      lambda model, x: model(
        x[0], # prev_image
        x[1], # cur_image
        x[2], # next_image
        x[3], # mask
        x[4], # intrinsic
        x[5], # extrinsic
        x[6], # ref_extrinsic
      )

# evaluators:
#   valid:
#     module: flame.engine
#     name: Evaluator.factory
#     kwargs:
#       model: model
#       data: data.valid
#       device: "'cuda'"
#       prepare_batch: prepare_batch
#       model_fn: >
#         lambda model, x: model(
#           x[0], # prev_image
#           x[1], # cur_image
#           x[2], # next_image
#           x[3], # mask
#           x[4], # intrinsic
#           x[5], # extrinsic
#           x[6], # ref_extrinsic
#         )
#     event: Events.EPOCH_COMPLETED
#     function: run
#   valid_train:
#     module: flame.engine
#     name: Evaluator.factory
#     kwargs:
#       model: model
#       data: data.valid_train
#       device: "'cuda'"
#       prepare_batch: prepare_batch
#       model_fn: >
#         lambda model, x: model(
#           x[0], # prev_image
#           x[1], # cur_image
#           x[2], # next_image
#           x[3], # mask
#           x[4], # intrinsic
#           x[5], # extrinsic
#           x[6], # ref_extrinsic
#         )
#     event: Events.ITERATION_COMPLETED(every=2000)
#     function: run

# metrics:
#   module: flame.handlers
#   name: Metrics
#   kwargs:
#     evaluators:
#       - evaluators.valid
#       - evaluators.valid_train
#     metrics:
#       loss:
#         module: metrics.loss
#         name: Loss
#         kwargs:
#           loss_fn: loss_fn

# lr_scheduler:
#   module: ignite.handlers.param_scheduler
#   name: ReduceLROnPlateauScheduler
#   kwargs:
#     optimizer: optimizer
#     metric_name: "'total_loss'"
#     mode: "'min'"
#     factor: 0.1
#     patience: 10
#   engine: evaluators.valid
#   event: Events.EPOCH_COMPLETED

# visualization:
#   module: handlers.visualizer
#   name: Visualizer
#   kwargs:
#     trainer: engine
#     evaluator: evaluators.valid_train
#     out_dir: "f'output/{experiment_name}/vis'"
#     out_name: "'visualization'"
#     out_resolution: (1928, 1414)  # nuscenes
#     fps: 2
#     file_ext: "'mp4'"
#     fourcc: "'mp4v'"
#     grid_nrow: 3
#     output_transform: 'lambda x: (x[0][2], x[1][8])'
#     event_name: Events.ITERATION_COMPLETED

logging:
  progress_bar:
    module: flame.handlers
    name: ProgressBar
    kwargs:
      trainer: engine
      # evaluators:
      #   valid: evaluators.valid
      #   valid_train: evaluators.valid_train
      metric_names:
        - "'total_loss'"

  tensorboard:
    module: flame.handlers
    name: Tensorboard
    kwargs:
      log_dir: "f'runs/{experiment_name}'"
      logger_handlers:
        - engine: engine
          event_name: Events.EPOCH_COMPLETED
          log_handler:
            module: ignite.contrib.handlers.tensorboard_logger
            name: OptimizerParamsHandler
            kwargs:
              optimizer: optimizer
        - engine: engine
          event_name: Events.ITERATION_COMPLETED(every=100)
          log_handler:
            module: ignite.contrib.handlers.tensorboard_logger
            name: OutputHandler
            kwargs:
              tag: "'training'"
              output_transform: "lambda loss: {'loss': loss}"
        # - engine: evaluators.valid_train
        #   event_name: Events.EPOCH_COMPLETED
        #   log_handler:
        #     module: ignite.contrib.handlers.tensorboard_logger
        #     name: OutputHandler
        #     kwargs:
        #       tag: "'evaluation/valid_train'"
        #       metric_names:
        #         - "'total_loss'"
        #         - "'reproj_loss'"
        #         - "'spatio_loss'"
        #         - "'spatio_tempo_loss'"
        #         - "'smooth_loss'"
        #       global_step_transform: global_step_from_engine(engine, Events.ITERATION_COMPLETED)
        # - engine: evaluators.valid
        #   event_name: Events.EPOCH_COMPLETED
        #   log_handler:
        #     module: ignite.contrib.handlers.tensorboard_logger
        #     name: OutputHandler
        #     kwargs:
        #       tag: "'evaluation/valid'"
        #       metric_names:
        #         - "'total_loss'"
        #         - "'reproj_loss'"
        #         - "'spatio_loss'"
        #         - "'spatio_tempo_loss'"
        #         - "'smooth_loss'"
        #       global_step_transform: global_step_from_engine(engine, Events.EPOCH_COMPLETED)
        - engine: engine
          event_name: Events.EPOCH_COMPLETED
          log_handler:
            module: ignite.contrib.handlers.tensorboard_logger
            name: GradsHistHandler
            kwargs:
              tag: "'grads'"
              model: model

# early_stopping:
#   module: flame.handlers
#   name: EarlyStopping
#   kwargs:
#     patience: 5
#     score_name: "'accuracy'"
#     mode: "'max'"
#     trainer: engine
#     evaluator: evaluators.valid
#   event: Events.EPOCH_COMPLETED

checkpoint:
  # best:
  #   module: flame.handlers
  #   name: BestCheckpoint
  #   kwargs:
  #     engine: evaluators.valid
  #     event: Events.EPOCH_COMPLETED
  #     modules:
  #       - "'model'"
  #     dirname: "f'checkpoints/{experiment_name}'"
  #     score_name: "'total_loss'"
  #     mode: "'min'"
  #     n_saved: 10
  #     global_step_transform: global_step_from_engine(engine, Events.EPOCH_COMPLETED)

  backup:
    module: flame.handlers
    name: BackupCheckpoint
    kwargs:
      engine: engine
      event: Events.EPOCH_COMPLETED
      modules:
        - "'model'"
        - "'engine'"
        - "'optimizer'"
        # - "'early_stopping'"
        # - "'lr_scheduler'"
        # - "'checkpoint.best'"
      dirname: "f'checkpoints/{experiment_name}'"
      n_saved: 5
      global_step_transform: global_step_from_engine(engine, Events.EPOCH_COMPLETED)

  loader:
    module: flame.handlers
    name: CheckpointLoader
    kwargs:
      path: null

  config_backup:
    module: flame.handlers
    name: ConfigBackup
    kwargs:
      backup_checkpoint: checkpoint.backup

extralibs:
  prepare_batch:
    module: datasets.utils
    name: prepare_batch
  Events:
    module: ignite.engine
    name: Events
  global_step_from_engine:
    module: ignite.handlers
    name: global_step_from_engine
